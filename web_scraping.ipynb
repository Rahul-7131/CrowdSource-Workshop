{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "web_scraping.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahul-7131/CrowdSource-Workshop/blob/main/web_scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bv1Ae0_c84S"
      },
      "source": [
        "<img style=\"width:600px;\" src=\"https://i.imgur.com/Kj8fCpd.png\" alt=\"aiadventures Logo\"/>\r\n",
        "\r\n",
        "<p align=\"center\"><a href=\"https://www.aiadventures.in\">Website </a> | <a href=\"https://www.instagram.com/aiadventures.pune/\">Instagram</a> | <a href=\"https://www.linkedin.com/company/aiadventures\">LinkedIn</a> | <a href=\"https://www.youtube.com/channel/UCPZqWUIXZAs926TBRclhUGw\">YouTube</a></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVWs1X0IXkI1"
      },
      "source": [
        "# Web Scraping 101\r\n",
        "\r\n",
        "### What & Why Web Scraping?\r\n",
        "Web is the greatest source of information. Web scraping, allows us to extract, parse, download and organize useful information from the web automatically.\r\n",
        "\r\n",
        "- Machine Learning & Data Science\r\n",
        "- Research\r\n",
        "- Business Intelligence\r\n",
        "- E-commerce Websites\r\n",
        "- Marketing and Sales Campaigns\r\n",
        "- Search Engine Optimization (SEO)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivpTAZjrXkU7"
      },
      "source": [
        "### Pre-requisites\r\n",
        "\r\n",
        "NO! But, having a prior know of the follow will surely help.\r\n",
        "- HTML & CSS\r\n",
        "- Basic understanding of HTML/DOM tree\r\n",
        "- Python basics\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILw65upeab5N"
      },
      "source": [
        "### Installations\r\n",
        "As `BeautifulSoup` is not a standard python library, we need to install it first. We will also need `requests` library to download content from web pages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An4g0BveZL9k"
      },
      "source": [
        "!pip install -q beautifulsoup4\r\n",
        "!pip install -q requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN37veWRXj-U"
      },
      "source": [
        "### Important links\r\n",
        "- [BeautifulSoup docs](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\r\n",
        "- http://toscrape.com/\r\n",
        "\r\n",
        "\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iovrppwUjhrT"
      },
      "source": [
        "# Coding Time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgX0fxeLpYVj"
      },
      "source": [
        "ai_html = \"\"\"\r\n",
        "<html>\r\n",
        "  <head>\r\n",
        "   <title>\r\n",
        "     Web Scraping 101 - by aiadventures\r\n",
        "   </title>\r\n",
        "  </head>\r\n",
        "  <body>\r\n",
        "    <div id=\"course\">\r\n",
        "      <h3> Courses at \r\n",
        "        <a href=\"www.aiadventures.in\">aiadventures</a>\r\n",
        "      </h3>\r\n",
        "      <ul>\r\n",
        "        <li>Python</li>\r\n",
        "        <li>Data Science</li>\r\n",
        "        <li>Machine Learning</li>\r\n",
        "        <li>Deep Learning</li>\r\n",
        "        <li>Computer Vision</li>\r\n",
        "      </ul>\r\n",
        "    </div>\r\n",
        "    <div class=\"follow_us\">\r\n",
        "      <h3> Follow Us </h3>\r\n",
        "      <ul>\r\n",
        "        <li><a href=\"https://www.instagram.com/aiadventures.pune\">Instagram</a></li>\r\n",
        "        <li><a href=\"https://www.linkedin.com/company/aiadventures\">LinkedIn</a></li>\r\n",
        "        <li><a href=\"https://medium.com/aiadventures\">Medium</a></li>\r\n",
        "        <li><a href=\"https://www.youtube.com/channel/UCPZqWUIXZAs926TBRclhUGw\">Youtube</a></li>\r\n",
        "      </ul>\r\n",
        "    </div>\r\n",
        "  </body>\r\n",
        "</html>\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Rf8vRFucC2T"
      },
      "source": [
        "CodePen: https://codepen.io/pen/\r\n",
        "\r\n",
        "Since, its just a string. We can use **string operations** & **regex** to extract meaningful informations from it. Even though, python has great support for working with strings. It still would be a lot of work.\r\n",
        "\r\n",
        "If you know HTML, then you might already know that all HTML documents have a common structure to it. This structure allowed developers to write very efficient HTML parsers. \r\n",
        "\r\n",
        "These parsers make it super easy to extract information from the HTML document. Parsers also provide ways of navigating, searching, and modifying the parse tree.\r\n",
        "\r\n",
        "[Beautiful Soup](http://www.crummy.com/software/BeautifulSoup/) is a Python library for extracting data out of HTML and XML files.\r\n",
        "\r\n",
        "There are many such libraries like [requests-html](https://requests.readthedocs.io/projects/requests-html/en/latest/index.html), [lxml](https://lxml.de/), [gazpacho](https://gazpacho.xyz/), etc. for parsing HTML docs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OflnFdi1YuMg"
      },
      "source": [
        "# import\r\n",
        "from bs4 import BeautifulSoup as bs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPZvtsHlrbg-"
      },
      "source": [
        "We start by creating a `soup` object which will help us to extract details.\r\n",
        "\r\n",
        "The input can be a *string*, or a *file object*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eyqnVe7smH1"
      },
      "source": [
        "soup = bs(ai_html)\r\n",
        "type(soup)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEczI-rksw92"
      },
      "source": [
        "soup.title"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Wade1Kwvc3Q"
      },
      "source": [
        "The output looks exactly the same. But under the hood, the complete string has being parsed and organised in the form of a tree, for easy access.\r\n",
        "\r\n",
        "### HTML Tags\r\n",
        "One of the most important elements in a HTML document are **tags**, which may contain other tags/strings. The easiest way to search a tag is to **search by its name**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itJThScclPkq"
      },
      "source": [
        "soup.find('title')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qM0206xyB3l"
      },
      "source": [
        "type(soup.find('title'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaXHtyCyx0Mo"
      },
      "source": [
        "**Note:** `find()` returns only the first tag/element. You can use `find_all()` to get a list of all the tags/elements.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg-lsu8kxvK_"
      },
      "source": [
        "soup.find_all('div')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utv7n9Kjyey0"
      },
      "source": [
        "type(soup.find_all('div'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiuvmHfPyhZF"
      },
      "source": [
        "Remember, `find()` returns a `tag` object and `find_all()` retuns a *ResultSet* object which is very similar to *python list*. So, it's very important to keep checking the data type. Because, it tells you, what operations are allowed.\r\n",
        "\r\n",
        "You can also select multiple tags by passing a list of tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1CXLcCMz7Gr"
      },
      "source": [
        "## Select both h3 and ul tags\r\n",
        "soup.find_all(['h3', 'ul'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHgYsvNiy3e5"
      },
      "source": [
        "### Tag attributes\r\n",
        "\r\n",
        "Sometimes, we want to select tags based on its attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFLI9hJu0hcs"
      },
      "source": [
        "soup.find('div', id='course')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU7xuJF3lPgf"
      },
      "source": [
        "soup.find('div', class_='follow_us')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G7wTNI2T95G"
      },
      "source": [
        "You can also select a tag by checking if an attribute is present or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5pas2n71cUX"
      },
      "source": [
        "## Selects all the 'div' which has 'id' attribute\r\n",
        "soup.find('div', id=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35WMpIbH4NXc"
      },
      "source": [
        "### Regex\r\n",
        "\r\n",
        "Instead of string, you can **use regular expressions** to select tags & also for attribute values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajixkasflPdG"
      },
      "source": [
        "import re\r\n",
        "soup.find(re.compile('di'), class_= re.compile('follow_us'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwpYebpY4cRB"
      },
      "source": [
        "### Accessing meaningful information\r\n",
        "\r\n",
        "So far, we have learnt how to select HTML tags. This is important because, once you have selected the elements, you can access all the information present inside it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYGf0r4S5LCA"
      },
      "source": [
        "title_tag = soup.find('title')\r\n",
        "title_tag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-waa6BtXGuB"
      },
      "source": [
        "To access the inner HTML, you can simple run `tag_element.text`. For example,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJUZTK8D5K5F"
      },
      "source": [
        "title_tag.text.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7mT8PyFXJ0z"
      },
      "source": [
        "You can also extract the attribute values as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCzqI6xNXOTG"
      },
      "source": [
        "a_tag = soup.find('a')\r\n",
        "a_tag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ka6B7gfXQv_"
      },
      "source": [
        "Once you have the tag, just think of it as a dictionary. You can easily access any attribute by passing it as a key."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8piB8vdXOPo"
      },
      "source": [
        "a_tag['href']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahZnhssfXVTG"
      },
      "source": [
        "You can extract all the links by running the following code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCk6yTbq5Ks3"
      },
      "source": [
        "[a_tag['href'] for a_tag in soup.find_all('a')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqUk0jEC6qT1"
      },
      "source": [
        "### Further Reading\r\n",
        "\r\n",
        "So far, we have just scratched the surface. But I think this is good enough to get you started with `BeautifulSoup` & to scrape most of the static pages on the web. `BeautifulSoup` has much more to offer, like \r\n",
        "- Searching the tree, [read more](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree)\r\n",
        "- CSS Selector, [read more](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors)\r\n",
        "- Navigating DOM tree, [read more](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#navigating-the-tree)\r\n",
        "- Manipulating Elements, [read more](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#modifying-the-tree)\r\n",
        "- and much more . . .\r\n",
        "\r\n",
        "I will highly recommend you to take some time and read more about `BeautifulSoup`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vElN6kp8aN9"
      },
      "source": [
        "# Scraping a Real web page\r\n",
        "\r\n",
        "### Web Scraping is not always the solution!\r\n",
        "Some websites offer data sets that are downloadable in CSV format, or accessible via an Application Programming Interfaces (APIs).\r\n",
        "\r\n",
        "For example, \r\n",
        "- IMDB\r\n",
        "- Netflix\r\n",
        "- Google, etc.\r\n",
        "\r\n",
        "### Legalities\r\n",
        "Generally, if you are going to use the scraped data for personal or educational purpose, then there may not be any problem. But if you are going to use it for commercial purpose then I will highly recommend you to do some background research about website's scraping policies as well about the data you are going to scrape.\r\n",
        "\r\n",
        "You should start with **robots.txt** file. After any website, simply write *robots.txt*. For example, www.google.com/robots.txt\r\n",
        "\r\n",
        "### Finally,\r\n",
        "Once you make sure that you are not breaking any law/policy, then you should spend some time **analysis the web page**.\r\n",
        "- View page source\r\n",
        "- Inspect DOM elements\r\n",
        "- Is the page static/dynamic ?\r\n",
        "- Is it using AJAX calls ?  \r\n",
        "\r\n",
        "In this workshop, we will scrape all the books from http://books.toscrape.com/ website. Its good time to analysis the page.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_AwX4EJq3hm"
      },
      "source": [
        "### `requests` library\r\n",
        "`requests` is python library used for accessing web pages. With the help of Requests, we can get the raw HTML of web pages which can then be parsed for retrieving the data.\r\n",
        "\r\n",
        "We will use `requests` library to download the contents of the web page. Because, `BeautifulSoup` needs an input document to create a `soup` object and it cannot fetch a web page by itself. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWxevsqudQqY"
      },
      "source": [
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exAMuLZdY1ag"
      },
      "source": [
        "url = 'http://books.toscrape.com/'\r\n",
        "response = requests.get(url)\r\n",
        "response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atxzeRI7cpY6"
      },
      "source": [
        "you can also check the status as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwJTYW6naZnz"
      },
      "source": [
        "response.status_code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1Bx6mOYa1pV"
      },
      "source": [
        "*200* means the request was successfully served. These are called **HTTP response status codes**. You can read more about them, [here](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status).\r\n",
        "\r\n",
        "Now, that the request to http://books.toscrape.com/ has been successfully served, we can get the all HTML text by calling `response.text`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkvXR4-JY_p4"
      },
      "source": [
        "print(response.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD7Qys14ZTnN"
      },
      "source": [
        "### `response.text` vs `response.content`\r\n",
        "\r\n",
        "- `text` is the content of the response in **Unicode**, and `content` is the content of the response in **bytes**.\r\n",
        "\r\n",
        "- `text` would be preferred for textual responses, such as an HTML or XML document, and `content` would be preferred for \"binary\" filetypes, such as an image or PDF file.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uhVd1FgZBg1"
      },
      "source": [
        "type(response.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIu5eO8WdtU5"
      },
      "source": [
        "Since, `response.text` is simply a python string, we can directly pass it to `BeautifulSoup`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0SfW0nghlPB"
      },
      "source": [
        "soup = bs(response.text)\r\n",
        "type(soup)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5LgswnIhtR4"
      },
      "source": [
        "soup.find('title').text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIMZVhaNC7ZF"
      },
      "source": [
        "books_tag = soup.find_all('article', class_='product_pod')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY1xt8aEDTTC"
      },
      "source": [
        "book_tag = books_tag[0]\r\n",
        "book_tag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPGG-yOfDq7h"
      },
      "source": [
        "## Title\r\n",
        "title = \r\n",
        "title"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr7_yCIEEYRa"
      },
      "source": [
        "## Rating\r\n",
        "rating = \r\n",
        "rating"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCfJOMJzEuyz"
      },
      "source": [
        "## Price\r\n",
        "price = \r\n",
        "price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4_u33FfgKKk"
      },
      "source": [
        "## Book link\r\n",
        "link = \r\n",
        "link"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtvfeoryGgKk"
      },
      "source": [
        "## function get_details"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HevZjhcngqx5"
      },
      "source": [
        "## function get_soup\r\n",
        "def get_soup(url):\r\n",
        "    resp = requests.get(url)\r\n",
        "    if resp.status_code == 200:\r\n",
        "        return bs(resp.text)\r\n",
        "    else: return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1Sm7wl5Ze2D"
      },
      "source": [
        "## function get_books"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlRCZPlihTBj"
      },
      "source": [
        "url = 'http://books.toscrape.com/'\r\n",
        "books = get_books(url)\r\n",
        "len(books)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-99VYU7h7cp"
      },
      "source": [
        "## function get_all_books. Add 'try/except' + 'pandas' + 'time'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaR5vXc0kLFm"
      },
      "source": [
        "df = get_all_books()\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wopf5-o6lxUE"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWfS3dyKRuqw"
      },
      "source": [
        "## Limitations:\r\n",
        "\r\n",
        "- Won't work for **dynamic pages**. But why is it so?\r\n",
        "    - Content generated by JavaScript code\r\n",
        "    - Content generated upon user action. For example; reaching the bottom of the page, etc.\r\n",
        "\r\n",
        "- Won't work for pages that need authentication. \r\n",
        "\r\n",
        "    Your browser hides a lot of complexity (like cookies) from you. If you want to programmatically access your account, then you will have to address all this complexity yourself. \r\n",
        "    \r\n",
        "    Its not impossible, but its a lot of work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2as3VebRuZb"
      },
      "source": [
        "url = 'http://quotes.toscrape.com/js/'\r\n",
        "soup = get_soup(url)\r\n",
        "len(soup.find_all('div', class_='quote'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYezySWTvawU"
      },
      "source": [
        "[Selenium](https://selenium-python.readthedocs.io/) is a powerful tool for controlling web browsers through programs and performing browser automation. Selenium test scripts can be written in any programming languages like Java, Python, C#, Ruby, Perl, as so on.\r\n",
        "\r\n",
        "Selenium runs a browser instance, allowing you to do everything that a normal human being can do. But its has a steep learning curve to it.😜\r\n",
        "\r\n",
        "Thank You all for your time. Hope you had a wonderful time, learning with [aiadventures](www.aiadventures.in)"
      ]
    }
  ]
}